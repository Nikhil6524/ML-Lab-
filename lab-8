import numpy as np
from collections import Counter

def entropy(labels):
    """Calculate entropy given a list of labels."""
    label_counts = Counter(labels)
    n_labels = len(labels)
    entropy = 0.0
    for count in label_counts.values():
        prob = count / n_labels
        entropy -= prob * np.log2(prob)
    return entropy

def information_gain(data, labels, feature_index):
    """Calculate information gain given data, labels, and feature index."""
    # Calculate total entropy before splitting
    total_entropy = entropy(labels)

    # Calculate weighted entropy after splitting
    unique_values = set(data[:, feature_index])
    weighted_entropy = 0.0
    for value in unique_values:
        subset_indices = np.where(data[:, feature_index] == value)[0]
        subset_labels = labels[subset_indices]
        weighted_entropy += len(subset_labels) / len(labels) * entropy(subset_labels)

    # Calculate information gain
    info_gain = total_entropy - weighted_entropy
    return info_gain

def find_root_feature(data, labels):
    """Find the root feature/attribute using Information Gain."""
    num_features = data.shape[1]
    max_info_gain = 0
    root_feature_index = None

    for i in range(num_features):
        info_gain = information_gain(data, labels, i)
        if info_gain > max_info_gain:
            max_info_gain = info_gain
            root_feature_index = i

    return root_feature_index
